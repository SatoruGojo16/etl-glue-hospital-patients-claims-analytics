{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Hospital Patient Claims\n",
    "## Raw to Staging\n",
    "##### You are now running a AWS Glue Studio notebook; To start using your notebook you need to start an AWS Glue Interactive Session.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "%idle_timeout 10\n",
    "%glue_version 5.0\n",
    "%worker_type G.1X\n",
    "%number_of_workers 2\n",
    "\n",
    "import sys\n",
    "import json \n",
    "import boto3\n",
    "from awsglue.transforms import *\n",
    "from awsglue.utils import getResolvedOptions\n",
    "from pyspark.context import SparkContext\n",
    "from awsglue.context import GlueContext\n",
    "from awsglue.job import Job\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import * \n",
    "from awsglue.dynamicframe import DynamicFrame\n",
    "import random \n",
    "from datetime import datetime\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "glueContext = GlueContext(sc)\n",
    "spark = glueContext.spark_session\n",
    "job = Job(glueContext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_secret():\n",
    "    secret_name = \"dev/hospital_patients_claims/redshift_connection\"\n",
    "    region_name = \"us-east-1\"\n",
    "    client = boto3.client(\n",
    "        service_name='secretsmanager',\n",
    "        region_name=region_name\n",
    "    )\n",
    "    try:\n",
    "        get_secret_value_response = client.get_secret_value(\n",
    "            SecretId=secret_name\n",
    "        )\n",
    "    except ClientError as e:\n",
    "        raise e\n",
    "    db_config = get_secret_value_response['SecretString']\n",
    "    return db_config\n",
    "\n",
    "db_config = json.loads(get_secret())\n",
    "my_conn_options = {\n",
    "    \"url\": db_config['dev_url'],\n",
    "    \"user\": db_config['dev_username'],\n",
    "    \"password\": db_config['dev_password'],\n",
    "    \"redshiftTmpDir\": db_config['dev_redshift_temp_directory'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "todays_date = datetime.today().strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_path = f's3://hospital-patients-claims-bucket/raw_zone/raw_hospital_patients_claims/load_date={todays_date}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = glueContext.create_data_frame.from_options(connection_type='s3', connection_options={\"paths\": [s3_path]}, format='parquet')\n",
    "df = df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trimming the Columns along with DataType defining\n",
    "df = df.withColumn('partition_key', F.trim(F.col('partition_key').cast(StringType()))) \\\n",
    "              .withColumn('patient_id', F.trim(F.col('patient_id').cast(StringType()))) \\\n",
    "              .withColumn('name_prefix', F.trim(F.col('name_prefix').cast(StringType()))) \\\n",
    "              .withColumn('first_name', F.trim(F.col('first_name').cast(StringType()))) \\\n",
    "              .withColumn('last_name', F.trim(F.col('last_name').cast(StringType()))) \\\n",
    "              .withColumn('date_of_birth', F.trim(F.col('date_of_birth').cast(StringType()))) \\\n",
    "              .withColumn('phone_number', F.trim(F.col('phone_number').cast(StringType()))) \\\n",
    "              .withColumn('email_id', F.trim(F.col('email_id').cast(StringType()))) \\\n",
    "              .withColumn('policy_id', F.trim(F.col('policy_id').cast(StringType()))) \\\n",
    "              .withColumn('policy_start_date', F.trim(F.col('policy_start_date').cast(StringType()))) \\\n",
    "              .withColumn('policy_end_date', F.trim(F.col('policy_end_date').cast(StringType()))) \\\n",
    "              .withColumn('preimum_amount', F.trim(F.col('preimum_amount').cast(StringType()))) \\\n",
    "              .withColumn('coverage_limit', F.trim(F.col('coverage_limit').cast(StringType()))) \\\n",
    "              .withColumn('address_id', F.trim(F.col('address_id').cast(StringType()))) \\\n",
    "              .withColumn('addressline', F.trim(F.col('addressline').cast(StringType()))) \\\n",
    "              .withColumn('borough', F.trim(F.col('borough').cast(StringType()))) \\\n",
    "              .withColumn('borough_level', F.trim(F.col('borough').cast(StringType()))) \\\n",
    "              .withColumn('borough_latitude', F.trim(F.col('borough_latitude').cast(StringType()))) \\\n",
    "              .withColumn('borough_longitude', F.trim(F.col('borough_longitude').cast(StringType()))) \\\n",
    "              .withColumn('city', F.trim(F.col('city').cast(StringType()))) \\\n",
    "              .withColumn('state', F.trim(F.col('state').cast(StringType()))) \\\n",
    "              .withColumn('claim_id', F.trim(F.col('claim_id').cast(StringType()))) \\\n",
    "              .withColumn('claim_initialized_date', F.trim(F.col('claim_initialized_date').cast(StringType()))) \\\n",
    "              .withColumn('claim_request_amount', F.trim(F.col('claim_request_amount').cast(StringType()))) \\\n",
    "              .withColumn('claim_rejected_reason', F.trim(F.col('claim_rejected_reason').cast(StringType()))) \\\n",
    "              .withColumn('source_file_path', F.trim(F.col('source_file_path').cast(StringType()))) \\\n",
    "              .withColumn('source_load_path', F.trim(F.col('source_load_path').cast(StringType()))) \\\n",
    "              .withColumn('load_timestamp', F.trim(F.col('load_timestamp').cast(StringType()))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering Unwanted Records\n",
    "df = df.drop_duplicates()\n",
    "# FIltering by NOT NULL Values on required ID Values\n",
    "df = df.filter(F.col('patient_id').isNotNull() & F.col('policy_id').isNotNull() & F.col('address_id').isNotNull() & F.col('claim_id').isNotNull())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Amount Column to be having Only Numbers - No Negative - Amount Column Format enforce\n",
    "df = df.withColumn('claim_request_amount', F.regexp_replace('claim_request_amount',r'\\$',''))\n",
    "df = df.withColumn('preimum_amount', F.regexp_replace('preimum_amount',r'\\$',''))\n",
    "df = df.withColumn('coverage_limit', F.regexp_replace('coverage_limit',r'\\$',''))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering records where amounts to be greater than 0\n",
    "df = df.where(df.claim_request_amount > 0)\n",
    "df = df.where(df.preimum_amount > 0)\n",
    "df = df.where(df.coverage_limit > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate High Risk Claims and add it as a Flag Indicator \n",
    "df = df.withColumn('high_risk_claim_flag', F.when(((df.claim_request_amount / df.coverage_limit) * 100) > 80, 'Y').otherwise('N'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rejected Claims with Rejected Reasons \n",
    "df = df.filter(~((df.claim_status == 'Rejected') & (df.claim_rejected_reason.isNull())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Enrichment of Borough Details Values\n",
    "df_borough_details = spark.read.csv('../lookup_files/lookup_data_london_borough_details.csv', header=True)\n",
    "combined_df = df.join(F.broadcast(df_borough_details), df.borough == df_borough_details.borough, 'left')\n",
    "\n",
    "# Enrich DataFrame with borough abbrevation and code of London \n",
    "df = combined_df.select(df['*'], 'borough_abbrev','borough_code') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all date-related columns to a standard date/timestamp type\n",
    "df = df.withColumn('date_of_birth', F.to_date(df.date_of_birth, 'dd-MM-yyyy'))\n",
    "df = df.withColumn('policy_start_date', F.to_date(df.policy_start_date,'dd/MM/yyyy'))\n",
    "df = df.withColumn('policy_end_date', F.to_date(df.policy_end_date, 'yyyy/MM/dd'))\n",
    "df = df.withColumn('claim_initialized_date', F.to_date(df.policy_end_date, 'dd/MM/yyyy'))\n",
    "\n",
    "\n",
    "# Policy End date should be greater than start date \n",
    "df = df.where(df.policy_end_date > df.policy_start_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Latitude and Longitude of the borogh\n",
    "df = df.withColumn('borough_latitude', F.regexp_extract('borough_latitude', r'[0-9]{1,3}.[0-9]{1,4}',0))\n",
    "df = df.withColumn('borough_longitude', F.regexp_extract('borough_longitude', r'[0-9]{1,3}.[0-9]{1,4}',0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Name Column to be having Only Letters - Replacing Invalid characters to EMPTY_STRING\n",
    "df = df.withColumn('first_name', F.regexp_replace(F.col('first_name'), '[^a-zA-Z]', ''))\n",
    "df = df.withColumn('last_name', F.regexp_replace(F.col('last_name'), '[^a-zA-Z]', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIAL Caps on Name Fields\n",
    "df = df.withColumn('first_name', F.initcap(F.col('first_name')))\n",
    "df = df.withColumn('last_name', F.initcap(F.col('last_name')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating Full Name for the patient\n",
    "df = df.withColumn('patient_full_name', F.concat_ws(' ',df.name_prefix,df.first_name,df.last_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check email format - Filtering invalid Email ID records - Can be Test Records\n",
    "df = df.filter(F.regexp_like(df.email_id, F.lit(r'^[a-z0-9_.+-]+@[a-z]+\\.[a-z]+$')) == True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Ph Number - Filtering invalid Phone No records - Can be Test Records\n",
    "df = df.filter(F.regexp_like('phone_number',F.lit(r\"^[\\+]44[0-9]{10}$\")) == True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Load Date\n",
    "df = df.withColumn('load_date',F.lit(todays_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing the data to Redshift Table - Staging Claims\n",
    "dyf = DynamicFrame.fromDF(df, glueContext, 'redshift_write_staging_claims')\n",
    "my_conn_options['dbtable'] = \"staging_claims_incremental_load\"\n",
    "glueContext.write_dynamic_frame.from_options(\n",
    "    connection_type=\"redshift\",\n",
    "    connection_options = my_conn_options,\n",
    "    frame = dyf,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
