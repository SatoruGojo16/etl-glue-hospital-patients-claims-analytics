{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "tags": []
   },
   "source": [
    "# Hospital Patient Claims\n",
    "## Staging to Curated "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "####  Run this cell to set up and start your interactive session.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "%idle_timeout 10\n",
    "%glue_version 5.0\n",
    "%worker_type G.1X\n",
    "%number_of_workers 2\n",
    "\n",
    "import sys\n",
    "from awsglue.transforms import *\n",
    "from awsglue.utils import getResolvedOptions\n",
    "from pyspark.context import SparkContext\n",
    "from awsglue.context import GlueContext\n",
    "from awsglue.job import Job\n",
    "import awsglue.transforms as  T\n",
    "import pyspark.sql.functions as  F\n",
    "from pyspark.sql.types import * \n",
    "from awsglue import DynamicFrame\n",
    "import json \n",
    "from datetime import date\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "  \n",
    "sc = SparkContext.getOrCreate()\n",
    "glueContext = GlueContext(sc)\n",
    "spark = glueContext.spark_session\n",
    "job = Job(glueContext)\n",
    "args = getResolvedOptions(sys.argv, ['JOB_NAME','is_init_load'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3, json\n",
    "def get_secret():\n",
    "    secret_name = \"dev/hospital_patients_claims/redshift_connection\"\n",
    "    region_name = \"us-east-1\"\n",
    "    client = boto3.client(\n",
    "        service_name='secretsmanager',\n",
    "        region_name=region_name\n",
    "    )\n",
    "    try:\n",
    "        get_secret_value_response = client.get_secret_value(\n",
    "            SecretId=secret_name\n",
    "        )\n",
    "    except ClientError as e:\n",
    "        raise e\n",
    "    db_config = get_secret_value_response['SecretString']\n",
    "    return db_config\n",
    "\n",
    "db_config = json.loads(get_secret())\n",
    "my_conn_options = {\n",
    "    \"url\": db_config['dev_url'],\n",
    "    \"user\": db_config['dev_username'],\n",
    "    \"password\": db_config['dev_password'],\n",
    "    \"redshiftTmpDir\": db_config['dev_redshift_temp_directory'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_load = args['is_init_load']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "todays_date = date.today().strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# incremental load table \n",
    "df_incremental_load_conn_options = my_conn_options\n",
    "my_conn_options['dbtable'] = \"staging_claims_incremental_load\"\n",
    "df_incremental_load_conn_options['sampleQuery'] = f\"Select * from staging_claims_incremental_load where load_date = '{todays_date}' \"\n",
    "df_incremental_load = glueContext.create_data_frame.from_options(\n",
    "    connection_type = 'redshift',\n",
    "    connection_options = df_incremental_load_conn_options,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# claim table \n",
    "df_staging_claims = df_incremental_load.select('claim_id','high_risk_claim_flag','claim_initialized_date','claim_request_amount','claim_status','claim_rejected_reason')\n",
    "\n",
    "# patient table \n",
    "df_staging_patient = df_incremental_load.select('patient_id','name_prefix','first_name','last_name','patient_full_name','date_of_birth','phone_number','email_id')\n",
    "\n",
    "# policy table \n",
    "df_staging_policy = df_incremental_load.select('policy_id','policy_start_date','policy_end_date','preimum_amount','coverage_limit')\n",
    "\n",
    "# address table \n",
    "df_staging_address = df_incremental_load.select('address_id','addressline','borough','borough_level','borough_latitude','borough_longitude','borough_abbrev','borough_code','city','state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "claims_insert_query_post_action =\"\"\"\n",
    "INSERT INTO dim_claims(claim_id,high_risk_claim_flag,claim_initialized_date,claim_request_amount,claim_status,claim_rejected_reason)\n",
    "SELECT claim_id,high_risk_claim_flag,claim_initialized_date,claim_request_amount,claim_status,claim_rejected_reason\n",
    "FROM staging_claims;\n",
    "\"\"\"\n",
    "# loading Staging Claims\n",
    "my_conn_options['dbtable'] = \"staging_claims\"\n",
    "my_conn_options['preactions'] = \"TRUNCATE \"+my_conn_options['dbtable']\n",
    "my_conn_options['postactions'] = claims_insert_query_post_action \n",
    "glueContext.write_dynamic_frame.from_options(\n",
    "    connection_type=\"redshift\",\n",
    "    connection_options = my_conn_options,\n",
    "    frame = DynamicFrame.fromDF(df_staging_claims, glueContext, 'redshift_write_claims'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_merge_query_post_action =\"\"\"\n",
    "\n",
    "UPDATE dim_patient \n",
    "SET is_current = 'N', effective_end_date = getdate()\n",
    "FROM staging_patient\n",
    "WHERE staging_patient.patient_id = dim_patient.patient_id\n",
    "and dim_patient.is_current = 'Y'\n",
    ";\n",
    "\n",
    "INSERT INTO dim_patient(patient_id,name_prefix,first_name,last_name,patient_full_name,date_of_birth,phone_number,email_id)\n",
    "SELECT patient_id,name_prefix,first_name,last_name,patient_full_name,date_of_birth,phone_number,email_id\n",
    "FROM staging_patient;\n",
    "\n",
    "\"\"\"\n",
    "# loading Stagting Patients\n",
    "my_conn_options['dbtable'] = \"staging_patient\"\n",
    "my_conn_options['preactions'] = \"TRUNCATE \"+my_conn_options['dbtable']\n",
    "my_conn_options['postactions'] = patient_merge_query_post_action \n",
    "glueContext.write_dynamic_frame.from_options(\n",
    "    connection_type=\"redshift\",\n",
    "    connection_options = my_conn_options,\n",
    "    frame = DynamicFrame.fromDF(df_staging_patient, glueContext, 'redshift_write_patient'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_merge_query_post_action =\"\"\"\n",
    "UPDATE dim_policy \n",
    "SET is_current = 'N', effective_end_date = getdate()\n",
    "FROM staging_policy\n",
    "WHERE staging_policy.policy_id = dim_policy.policy_id\n",
    "and dim_policy.is_current = 'Y'\n",
    ";\n",
    "\n",
    "INSERT INTO dim_policy(policy_id,policy_start_date,policy_end_date,premium_amount,coverage_limit)\n",
    "SELECT policy_id,policy_start_date,policy_end_date,preimum_amount,coverage_limit\n",
    "FROM staging_policy;\n",
    "\n",
    "\"\"\"\n",
    "# loading Staging Policy\n",
    "my_conn_options['dbtable'] = \"staging_policy\"\n",
    "my_conn_options['preactions'] = \"TRUNCATE \"+my_conn_options['dbtable']\n",
    "my_conn_options['postactions'] = policy_merge_query_post_action \n",
    "glueContext.write_dynamic_frame.from_options(\n",
    "    connection_type=\"redshift\",\n",
    "    connection_options = my_conn_options,\n",
    "    frame =  DynamicFrame.fromDF(df_staging_policy, glueContext, 'redshift_write_policy'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address_merge_query_post_action =\"\"\"\n",
    "\n",
    "UPDATE dim_address \n",
    "SET is_current = 'N', effective_end_date = getdate()\n",
    "FROM staging_address\n",
    "WHERE staging_address.address_id = dim_address.address_id\n",
    "and dim_address.is_current = 'Y'\n",
    ";\n",
    "\n",
    "INSERT INTO dim_address(address_id,addressline,borough,borough_level,borough_latitude,borough_longitude,borough_abbrev,borough_code,city,state)\n",
    "SELECT address_id,addressline,borough,borough_level,borough_latitude,borough_longitude,borough_abbrev,borough_code,city,state\n",
    "FROM staging_address;\n",
    "\n",
    "\"\"\"\n",
    "# loading Staging Address\n",
    "my_conn_options['dbtable'] = \"staging_address\"\n",
    "my_conn_options['preactions'] = \"TRUNCATE \"+my_conn_options['dbtable']\n",
    "my_conn_options['postactions'] = address_merge_query_post_action \n",
    "glueContext.write_dynamic_frame.from_options(\n",
    "    connection_type=\"redshift\",\n",
    "    connection_options = my_conn_options,\n",
    "    frame = DynamicFrame.fromDF(df_staging_address, glueContext, 'redshift_write_address'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "490327ae-149c-4f76-9ae7-22bf76d83c9d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# loading Curated Dim Date\n",
    "if initial_load:\n",
    "    dim_date = spark.sql('''\n",
    "    SELECT explode(sequence(to_date('2000-01-01'), to_date('2030-01-01'), interval 1 months)) as date\n",
    "    ''')\n",
    "    dim_date_cols = {\n",
    "    \"date_id\":date_format(dim_date.date,'MMdd'),\n",
    "    \"month\":date_format(dim_date.date, 'M'),\n",
    "    \"month_short\":date_format(dim_date.date, \"LLL\"), \n",
    "    \"month_long\":date_format(dim_date.date, \"LLLL\"),\n",
    "    \"year_short\":date_format(dim_date.date, 'yy'),\n",
    "    \"year_long\":date_format(dim_date.date, 'yyyy'),\n",
    "    \"quarter\":ceil(date_format(dim_date.date, 'M')/3),\n",
    "    }\n",
    "    dim_date = dim_date.withColumns(dim_date_cols)\n",
    "    dim_date = dim_date.drop('date')\n",
    "    dfy_dim_date = DynamicFrame.fromDF(dim_date, glueContext, 'redshift_write_dim_date')\n",
    "    my_conn_options['dbtable'] = \"dim_date\"\n",
    "    glueContext.write_dynamic_frame.from_options(\n",
    "        connection_type=\"redshift\",\n",
    "        connection_options = my_conn_options,\n",
    "        frame = dfy_dim_date\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_table_insert_query_post_action =\"\"\"\n",
    "\n",
    "INSERT INTO fact_claims_hist(patient_ref_key,claim_ref_key,address_ref_key,policy_ref_key,last_updated_date)\n",
    "(\n",
    "SELECT \n",
    "dim_patient.patient_ref_key,\n",
    "dim_claims.claim_ref_key,\n",
    "dim_address.address_ref_key,\n",
    "dim_policy.policy_ref_key,\n",
    "getdate() last_updated_date\n",
    "FROM staging_claims_incremental_load\n",
    "join dim_claims on staging_claims_incremental_load.claim_id = dim_claims.claim_id\n",
    "join dim_patient on staging_claims_incremental_load.patient_id = dim_patient.patient_id and dim_patient.is_current = 'Y' and dim_patient.effective_end_date is NULL \n",
    "join dim_address on staging_claims_incremental_load.address_id = dim_address.address_id and dim_address.is_current = 'Y' and dim_address.effective_end_date is NULL \n",
    "join dim_policy on staging_claims_incremental_load.policy_id = dim_policy.policy_id and dim_policy.is_current = 'Y' and dim_policy.effective_end_date is NULL \n",
    ");\n",
    "\n",
    "\"\"\"\n",
    "# loading dim claims Incremental Load \n",
    "my_conn_options['dbtable'] = \"dim_claims_incremental_load\"\n",
    "my_conn_options['postactions'] = fact_table_insert_query_post_action\n",
    "glueContext.write_dynamic_frame.from_options(\n",
    "    connection_type=\"redshift\",\n",
    "    connection_options = my_conn_options,\n",
    "    frame = DynamicFrame.fromDF(df_incremental_load, glueContext, 'redshift_write_claims_incremental_load') ,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "staging_to_curated",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
